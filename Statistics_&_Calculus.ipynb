{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NinaNikolova/data_mining/blob/main/Statistics_%26_Calculus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0WiNbfjOKs1"
      },
      "source": [
        "# Statistics & Calculus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfse95sBOKs3"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_u5RIUXOKs3"
      },
      "source": [
        "## Libraries\n",
        "Today we will use the following libraries: NumPy, Math, Statistics, SciPy, SymPy and Pandas\n",
        "\n",
        "** [10 Best Math Libraries for Python](https://linuxhint.com/10_best_math_libraries_python/)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsOEV0jvOKs4"
      },
      "source": [
        "## SciPy\n",
        "SciPy is an Open Source Python-based library, which is used in mathematics, scientific computing, Engineering, and technical computing.\n",
        "\n",
        "__Sub-packages of SciPy:__\n",
        "\n",
        "- File input/output - [scipy.io](https://docs.scipy.org/doc/scipy/reference/io.html)\n",
        "- Special Function - [scipy.special](https://docs.scipy.org/doc/scipy/reference/special.html)\n",
        "- Linear Algebra Operation - [scipy.linalg](https://docs.scipy.org/doc/scipy/reference/linalg.html)\n",
        "- Interpolation - [scipy.interpolate](https://docs.scipy.org/doc/scipy/reference/interpolate.html)\n",
        "- Optimization and fit - [scipy.optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)\n",
        "- Statistics and random numbers - [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html)\n",
        "- Numerical Integration - [scipy.integrate](https://docs.scipy.org/doc/scipy/reference/integrate.html)\n",
        "- Fast Fourier transforms - [scipy.fftpack](https://docs.scipy.org/doc/scipy/reference/fftpack.html)\n",
        "- Signal Processing - [scipy.signal](https://docs.scipy.org/doc/scipy/reference/signal.html)\n",
        "- Image manipulation ‚Äì [scipy.ndimage](https://docs.scipy.org/doc/scipy/reference/ndimage.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvgqVp1DOKs5"
      },
      "source": [
        "### Special Package\n",
        "\n",
        "- scipy.special package contains numerous functions of mathematical physics.\n",
        "- SciPy special function includes Cubic Root, Exponential, Log sum Exponential, Lambert, __Permutation__ and __Combinations__, Gamma, Bessel, hypergeometric, Kelvin, beta, parabolic cylinder, Relative Error Exponential, etc.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md2rX4-aOKs5"
      },
      "source": [
        "### Permutations & Combinations\n",
        "SciPy also gives functionality to calculate Permutations and Combinations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WexGOWPHOKs5"
      },
      "source": [
        "#### Combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIX_IVOvOKs6"
      },
      "source": [
        "Combinations:\n",
        "$$\\mathbf{C}_n^k = \\mathbf{C}(n,k) = {n \\choose k} = \\frac{n!}{k!(n-k)!}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IsG9kx1OKs6"
      },
      "source": [
        "Combinations with repetition:\n",
        "$$\\mathbf{C}_n^k = \\mathbf{C}_{n + k - 1}^k = {n + k - 1\\choose k} = \\frac{(n + k - 1)!}{k!(n - 1)!}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "WD8HNZ1tOKs6",
        "outputId": "7df0e132-684c-4465-eadd-3ce1b19c7ed5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15.0"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.special import comb\n",
        "\n",
        "#find combinations of 5, 2 values using comb(N, k)\n",
        "com = comb(5, 2, exact = False, repetition=True)\n",
        "com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D06bcS6gOKs8"
      },
      "source": [
        "#### Permutations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVUN84o6OKs8"
      },
      "source": [
        "Permutations:\n",
        "$$P(n,k) = \\underbrace{n\\cdot(n-1)\\cdot(n-2)\\cdots(n-k+1)}_{k\\ \\mathrm{factors}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rk-03LGOKs8",
        "outputId": "d5025c03-9027-49c8-8e42-4cf6e30619f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.special import perm\n",
        "\n",
        "#find permutation of 5, 2 using perm (N, k) function\n",
        "per = perm(5, 2, exact = True)\n",
        "per"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXnYNv4lOKs8"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeOfQy8xOKs9"
      },
      "source": [
        "## Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "I1S0_5exOKs9"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import statistics\n",
        "import scipy.stats\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6xLJZS0OKs9"
      },
      "source": [
        "First we will create two lists - with and without NaN values. Second we will show how to check if a value is NaN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TkJMmTvrOKs9"
      },
      "outputs": [],
      "source": [
        "x = [8.0, 1, 2.5, 4, 28.0]\n",
        "x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6xnGmNrOKs-",
        "outputId": "de030ce1-e7df-453b-d511-4516f327fdc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math.isnan(np.nan), np.isnan(math.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRQvY30HOKs-",
        "outputId": "879ffc71-cde0-4ecf-e89f-44587fafcee5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.nan\n",
        "a == a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC8PI6jqOKs-",
        "outputId": "e4595481-dd06-4380-e097-7fe660f4b5d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math.isnan(x_with_nan[3]), np.isnan(x_with_nan[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtVTIyH_OKs_"
      },
      "source": [
        "_* Please note that __None__ is different from __NaN__!_  \n",
        "[What is the difference between NaN and None?](https://stackoverflow.com/questions/17534106/what-is-the-difference-between-nan-and-none)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY0aM3IkOKs_",
        "outputId": "e6579f78-e0f9-4315-b71c-e4fd62bdd616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None==None : True\n",
            "None==NaN  : False\n",
            "NaN==NaN   : False\n"
          ]
        }
      ],
      "source": [
        "print('None==None :', None==None)\n",
        "print('None==NaN  :', None==np.nan)\n",
        "print('NaN==NaN   :', np.nan==np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRz10c3MOKs_"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mu8tD8WOKs_"
      },
      "source": [
        "### Measures of Central Tendency\n",
        "The measures of central tendency show the central or middle values of datasets. We will look at the following measures of central tendency:\n",
        "- Mean\n",
        "- Weighted mean\n",
        "- Geometric mean\n",
        "- Harmonic mean\n",
        "- Median\n",
        "- Mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNjk0i6xOKs_"
      },
      "source": [
        "### Mean\n",
        "\n",
        "$$\\bar{x} = \\frac{1}{n}\\left (\\sum_{i=1}^n{x_i}\\right ) = \\frac{x_1+x_2+\\cdots +x_n}{n}$$\n",
        "\n",
        "The sample mean, also called the sample arithmetic mean or simply the average, is the arithmetic average of all the items in a dataset. The figure below illustrates the mean of a sample with five data points:\n",
        "\n",
        "<img src=\"images/mean.png\">\n",
        "\n",
        "The green dots represent the data points 1, 2.5, 4, 8, and 28. The red dashed line is their mean, or (1 + 2.5 + 4 + 8 + 28) / 5 = 8.7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4pBgJ6nOKs_"
      },
      "source": [
        "<div style=\"background-color:#b2b2ff; border-style: solid; border-color: blue; padding: 5px 5px 5px 5px;\" >\n",
        "<font color='blue' background-color='red'>\n",
        "___Note:___\n",
        "<br/>\n",
        "*Below are various methods for calculating the mean. These include conversions with pure Python, NumPy, Statistics, SciPy and Pandas. We should note that the library __SciPy.stats__ does not have a __\"mean\"__ function. __It is located in _Scipy_ directly and will be removed in _SciPy 2.0.0_!__ The function __\"mean\"__ is applied over two different lists - with and without NaN values. Only NumPy (methods starting with \"nan\") and Pandas can handle NaN values. __For the other methods we will not show an example with every library because the described here is similar to the other functions!__*\n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnRAorn2OKtA",
        "outputId": "6db9808b-bd4b-45d1-d129-0d3dc9c2659e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_lib             : 0.0\n"
          ]
        }
      ],
      "source": [
        "def printf(lib, val):\n",
        "    print('{0:20s} : {1}'.format(lib, val))\n",
        "printf('test_lib', 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-esbSUvOKtA",
        "outputId": "9b1bac54-64af-4d3b-ddee-90bb57ebcce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : 8.7\n",
            "statistics           : 8.7\n",
            "scipy                : 8.7\n",
            "np                   : 8.7\n",
            "np                   : 8.7\n",
            "Series               : 8.7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: scipy.mean is deprecated and will be removed in SciPy 2.0.0, use numpy.mean instead\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "# Pure Python\n",
        "printf('Python', sum(x) / len(x))\n",
        "\n",
        "# Math Library\n",
        "# print(math.mean(x)) # Without mean\n",
        "\n",
        "# Statistics Library\n",
        "printf('statistics', statistics.mean(x))\n",
        "# print(statistics.fmean(x))  # Python 3.8\n",
        "\n",
        "# SciPy Library\n",
        "printf('scipy', scipy.mean(x))\n",
        "\n",
        "# NumPy\n",
        "printf('np', np.mean(x))\n",
        "printf('np', np.array(x).mean())\n",
        "\n",
        "# Pandas\n",
        "printf('Series', pd.Series(x).mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whiUoiczOKtA",
        "outputId": "87f2603a-d742-460e-fe92-f7ac1db2917f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : nan\n",
            "statistics           : nan\n",
            "scipy                : nan\n",
            "np                   : nan\n",
            "np                   : nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: scipy.mean is deprecated and will be removed in SciPy 2.0.0, use numpy.mean instead\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "printf('Python', sum(x_with_nan) / len(x_with_nan))\n",
        "printf('statistics', statistics.mean(x_with_nan))\n",
        "# print(statistics.fmean(x_with_nan))  # Python 3.8\n",
        "printf('scipy', scipy.mean(x_with_nan))\n",
        "printf('np', np.mean(x_with_nan))\n",
        "printf('np', np.array(x_with_nan).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTj-7PaWOKtA",
        "outputId": "c85ca6ec-bac7-4749-e812-9f03c3fe7af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "np.nan               : 8.7\n",
            "Series               : 8.7\n"
          ]
        }
      ],
      "source": [
        "printf('np.nan', np.nanmean(x_with_nan))\n",
        "printf('Series', pd.Series(x_with_nan).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSz_jhg-OKtB"
      },
      "source": [
        "### Weighted Mean\n",
        "\n",
        "$$\\bar{x} = \\frac{ \\sum\\limits_{i=1}^n w_i x_i}{\\sum\\limits_{i=1}^n w_i} = \\frac{w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n}{w_1 + w_2 + \\cdots + w_n}$$\n",
        "\n",
        "The weighted mean, also called the weighted arithmetic mean or weighted average, is a generalization of the arithmetic mean that enables you to define the relative contribution of each data point to the result.\n",
        "\n",
        "You define one weight ùë§·µ¢ for each data point ùë•·µ¢ of the dataset ùë•, where ùëñ = 1, 2, ‚Ä¶, ùëõ and ùëõ is the number of items in ùë•. Then, you multiply each data point with the corresponding weight, sum all the products, and divide the obtained sum with the sum of weights: Œ£·µ¢(ùë§·µ¢ùë•·µ¢) / Œ£·µ¢ùë§·µ¢."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mixl8BOKtB"
      },
      "source": [
        "_Note: It‚Äôs convenient (and usually the case) that all weights are nonnegative, ùë§·µ¢ ‚â• 0, and that their sum is equal to one, or Œ£·µ¢ùë§·µ¢ = 1._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDqZ8RUlOKtB"
      },
      "source": [
        "The weighted mean is very handy when you need the mean of a dataset containing items that occur with given relative frequencies. For example, say that you have a set in which 20% of all items are equal to 2, 50% of the items are equal to 4, and the remaining 30% of the items are equal to 8. You can calculate the mean of such a set like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMhuX9ybOKtB",
        "outputId": "8118e505-8174-4a59-a20f-a4fa73b09157"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.8"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0.2 * 2 + 0.5 * 4 + 0.3 * 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErlbniNEOKtB"
      },
      "source": [
        "Here, you take the frequencies into account with the weights. With this method, you don‚Äôt need to know the total number of items.\n",
        "\n",
        "You can implement the weighted mean in pure Python by combining sum() with either range() or zip():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpH9NiJfOKtB",
        "outputId": "0c36bfa7-aeea-4aac-fba7-d7ccf964cfb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python w/ range      : 6.95\n",
            "Python w/ zip        : 6.95\n"
          ]
        }
      ],
      "source": [
        "#x = [8.0, 1, 2.5, 4, 28.0]\n",
        "w = [0.1, 0.2, 0.3, 0.25, 0.15]\n",
        "printf('Python w/ range', sum(w[i] * x[i] for i in range(len(x))) / sum(w))\n",
        "printf('Python w/ zip', sum(x_ * w_ for (x_, w_) in zip(x, w)) / sum(w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QI0BS5QzOKtC",
        "outputId": "346601bb-bb61-40f3-a0c1-1a71cde1e9cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "np.avg w/ np.array   : 6.95\n",
            "np.avg w/ series     : 6.95\n"
          ]
        }
      ],
      "source": [
        "x_np_arr, x_series, w_np_arr = np.array(x), pd.Series(x), np.array(w)\n",
        "printf('np.avg w/ np.array', np.average(x_np_arr, weights=w))\n",
        "printf('np.avg w/ series', np.average(x_series, weights=w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh-sbgmAOKtC",
        "outputId": "a23bdf4b-386a-4ef2-a46f-6c61f3f05986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : 6.95\n"
          ]
        }
      ],
      "source": [
        "printf('Python', (w_np_arr * x_np_arr).sum() / w_np_arr.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhVllLjSOKtD",
        "outputId": "941e0f26-693e-4d27-a9b7-f4adf2cd0c03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : nan\n",
            "np.avg               : nan\n"
          ]
        }
      ],
      "source": [
        "w_np_arr = np.array([0.1, 0.2, 0.3, 0.0, 0.2, 0.1])\n",
        "printf('Python', (w_np_arr * x_with_nan).sum() / w_np_arr.sum())\n",
        "printf('np.avg', np.average(x_with_nan, weights=w_np_arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZm_jTjHOKtD"
      },
      "source": [
        "### Harmonic Mean\n",
        "\n",
        "$$\\bar{x} = n \\left ( \\sum_{i=1}^n \\frac{1}{x_i} \\right ) ^{-1} = \\frac{n}{\\frac1{x_1} + \\frac1{x_2} + \\cdots + \\frac1{x_n}}$$\n",
        "\n",
        "The harmonic mean is the reciprocal of the mean of the reciprocals of all items in the dataset: ùëõ / Œ£·µ¢(1/ùë•·µ¢), where ùëñ = 1, 2, ‚Ä¶, ùëõ and ùëõ is the number of items in the dataset ùë•. One variant of the pure Python implementation of the harmonic mean is this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExBuEnMYOKtD",
        "outputId": "c19dc204-6a5e-43f7-f1f8-820a2687ca98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : 2.7613412228796843\n",
            "statistics           : 2.7613412228796843\n",
            "scipy                : 2.7613412228796843\n"
          ]
        }
      ],
      "source": [
        "printf('Python', len(x) / sum(1 / item for item in x))\n",
        "printf('statistics', statistics.harmonic_mean(x))\n",
        "printf('scipy', scipy.stats.hmean(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjFqsZz3OKtD",
        "outputId": "9741005b-cd82-45f6-d39c-9a5e7382aceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : nan\n",
            "statistics           : nan\n",
            "scipy                : ValueError: Harmonic mean only defined if all elements greater than zero\n"
          ]
        }
      ],
      "source": [
        "printf('Python', len(x_with_nan) / sum(1 / item for item in x_with_nan))\n",
        "printf('statistics', statistics.harmonic_mean(x_with_nan))\n",
        "# print(scipy.stats.hmean(x_with_nan))  # ValueError: Harmonic mean only defined if all elements greater than zero\n",
        "printf('scipy', 'ValueError: Harmonic mean only defined if all elements greater than zero')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfYZqn7EOKtE",
        "outputId": "9ee2048b-e1b6-4a1d-cf4b-7c859915759e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "statistics w/ NaN    : nan\n",
            "statistics w/ 0      : 0\n",
            "statistics w/ <0     : StatisticsError: harmonic mean does not support negative values\n"
          ]
        }
      ],
      "source": [
        "printf('statistics w/ NaN', statistics.harmonic_mean(x_with_nan))\n",
        "printf('statistics w/ 0', statistics.harmonic_mean([1, 0, 2]))\n",
        "# print(statistics.harmonic_mean([1, 2, -2]))  # StatisticsError: harmonic mean does not support negative values\n",
        "printf('statistics w/ <0', 'StatisticsError: harmonic mean does not support negative values')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCfcVOuXOKtE"
      },
      "source": [
        "### Geometric Mean\n",
        "\n",
        "$$\\bar{x} = \\left( \\prod_{i=1}^n{x_i} \\right )^\\frac{1}{n} = \\left(x_1 x_2 \\cdots x_n \\right)^\\frac{1}{n} = \\sqrt[n]{x_1 x_2 \\cdots x_n}$$\n",
        "\n",
        "The geometric mean is the ùëõ-th root of the product of all ùëõ elements ùë•·µ¢ in a dataset ùë•: ‚Åø‚àö(Œ†·µ¢ùë•·µ¢), where ùëñ = 1, 2, ‚Ä¶, ùëõ. The following figure illustrates the arithmetic, harmonic, and geometric means of a dataset:\n",
        "\n",
        "<img src=\"images/gmean.png\">\n",
        "\n",
        "Again, the green dots represent the data points 1, 2.5, 4, 8, and 28. The red dashed line is the mean. The blue dashed line is the harmonic mean, and the yellow dashed line is the geometric mean.\n",
        "\n",
        "You can implement the geometric mean in pure Python like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m6QAqZloOKtE"
      },
      "outputs": [],
      "source": [
        "gmean = 1\n",
        "for item in x:\n",
        "    gmean *= item\n",
        "gmean **= 1 / len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyub5kdCOKtE",
        "outputId": "abc4e43a-a961-4998-9b59-fdb7d27c98c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : 4.677885674856041\n",
            "statistics           : Python 3.8++\n",
            "scipy                : 4.67788567485604\n"
          ]
        }
      ],
      "source": [
        "printf('Python', gmean)\n",
        "# print(statistics.geometric_mean(x))  # Python 3.8\n",
        "printf('statistics', 'Python 3.8++')\n",
        "printf('scipy', scipy.stats.gmean(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oTGDq4HOKtE",
        "outputId": "43851a85-2690-4a55-8375-933a56cb4a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "statistics           : Python 3.8++\n",
            "scipy                : nan\n"
          ]
        }
      ],
      "source": [
        "# print(statistics.geometric_mean(x_with_nan))  # Python 3.8\n",
        "printf('statistics', 'Python 3.8++')\n",
        "printf('scipy', scipy.stats.gmean(x_with_nan))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMbwkUnpOKtE"
      },
      "source": [
        "<font color='blue'>___If you have nan values in a dataset, then gmean() will return nan. If there‚Äôs at least one 0, then it‚Äôll return 0.0 and give a warning. If you provide at least one negative number, then you‚Äôll get nan and the warning.___</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlQzmjApOKtF"
      },
      "source": [
        "#### How to Choose the Correct Mean?\n",
        "We have reviewed three different ways of calculating the average or mean of a variable or dataset. The arithmetic mean is the most commonly used mean, although it may not be appropriate in some cases.\n",
        "\n",
        "Each mean is appropriate for different types of data. For example:\n",
        "* If values have the same units: Use the arithmetic mean.\n",
        "* If values have differing units: Use the geometric mean.\n",
        "* If values are rates: Use the harmonic mean.\n",
        "\n",
        "The exceptions are if the data contains negative or zero values, then the geometric and harmonic means cannot be used directly.\n",
        "\n",
        "_* For more information and good explanation about different types of __mean__, please refer to [this post](https://towardsdatascience.com/on-average-youre-using-the-wrong-average-geometric-harmonic-means-in-data-analysis-2a703e21ea0)._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwH1oRhpOKtF"
      },
      "source": [
        "### Median\n",
        "\n",
        "$$\\mathrm{Me}(x) = \\frac{x_{\\left\\lfloor\\frac{l+1}{2}\\right\\rfloor} + x_{\\left\\lceil\\frac{l+1}{2}\\right\\rceil}}{2}$$\n",
        "\n",
        "The sample median is the middle element of a sorted dataset. The dataset can be sorted in increasing or decreasing order. If the number of elements ùëõ of the dataset is odd, then the median is the value at the middle position: 0.5(ùëõ + 1). If ùëõ is even, then the median is the arithmetic mean of the two values in the middle, that is, the items at the positions 0.5ùëõ and 0.5ùëõ + 1.\n",
        "\n",
        "For example, if you have the data points 2, 4, 1, 8, and 9, then the median value is 4, which is in the middle of the sorted dataset (1, 2, 4, 8, 9). If the data points are 2, 4, 1, and 8, then the median is 3, which is the average of the two middle elements of the sorted sequence (2 and 4). The following figure illustrates this:\n",
        "\n",
        "<img src=\"images/median.png\">\n",
        "\n",
        "The data points are the green dots, and the purple lines show the median for each dataset. The median value for the upper dataset (1, 2.5, 4, 8, and 28) is 4. If you remove the outlier 28 from the lower dataset, then the median becomes the arithmetic average between 2.5 and 4, which is 3.25.\n",
        "\n",
        "The figure below shows both the mean and median of the data points 1, 2.5, 4, 8, and 28:\n",
        "\n",
        "<img src=\"images/median_mean.png\">\n",
        "\n",
        "Again, the mean is the red dashed line, while the median is the purple line.\n",
        "\n",
        "The main difference between the behavior of the mean and median is related to dataset outliers or extremes. The mean is heavily affected by outliers, but the median only depends on outliers either slightly or not at all. Consider the following figure:\n",
        "\n",
        "<img src=\"images/median_mean_2.png\">\n",
        "\n",
        "The upper dataset again has the items 1, 2.5, 4, 8, and 28. Its mean is 8.7, and the median is 5, as you saw earlier. The lower dataset shows what‚Äôs going on when you move the rightmost point with the value 28:\n",
        "\n",
        "- If you increase its value (move it to the right), then the mean will rise, but the median value won‚Äôt ever change.\n",
        "- If you decrease its value (move it to the left), then the mean will drop, but the median will remain the same until the value of the moving point is greater than or equal to 4.\n",
        "You can compare the mean and median as one way to detect outliers and asymmetry in your data. Whether the mean value or the median value is more useful to you depends on the context of your particular problem.\n",
        "\n",
        "Here is one of many possible pure Python implementations of the median:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kyshIKovOKtF"
      },
      "outputs": [],
      "source": [
        "n = len(x)\n",
        "if n % 2:\n",
        "    median = sorted(x)[round(0.5*(n-1))]\n",
        "else:\n",
        "    x_ord, index = sorted(x), round(0.5 * n)\n",
        "    median = 0.5 * (x_ord[index-1] + x_ord[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-ZUi0goOKtF",
        "outputId": "2ddc35d9-9507-4f3a-9471-aa5f60025ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : 4\n",
            "statistics           : 4\n",
            "numpy                : 4.0\n"
          ]
        }
      ],
      "source": [
        "printf('Python', median)\n",
        "printf('statistics', statistics.median(x))\n",
        "printf('numpy', np.median(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uygnVCZOKtF",
        "outputId": "1dd08e13-dcf3-40cb-b67e-444322435fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2.5, 4, 8.0, 28.0]\n",
            "[1, 2.5, 4, 8.0]\n",
            "\n",
            "statistics.median    : 3.25\n",
            "statistics.low       : 2.5\n",
            "statistics.high      : 4\n"
          ]
        }
      ],
      "source": [
        "print(sorted(x))\n",
        "print(sorted(x[:-1]))\n",
        "print()\n",
        "printf('statistics.median', statistics.median(x[:-1]))\n",
        "printf('statistics.low', statistics.median_low(x[:-1]))\n",
        "printf('statistics.high', statistics.median_high(x[:-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8beDlM9LOKtF",
        "outputId": "c6fe8976-ff40-4fd6-c750-c60884be1e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2.5, 4, 8.0, nan, 28.0]\n",
            "\n",
            "statistics           : 6.0\n",
            "np.nan               : 4.0\n"
          ]
        }
      ],
      "source": [
        "print(sorted(x_with_nan))\n",
        "print()\n",
        "printf('statistics', statistics.median(x_with_nan))\n",
        "printf('np.nan', np.nanmedian(x_with_nan))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "TPX1bqYOOKtG",
        "outputId": "14f7536d-30d3-46d8-ce9a-e859f1cbe81e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "statistics.median    : 6.0\n",
            "statistics.low       : 4\n",
            "statistics.high      : 8.0\n"
          ]
        }
      ],
      "source": [
        "printf('statistics.median', statistics.median(x_with_nan))\n",
        "printf('statistics.low', statistics.median_low(x_with_nan))\n",
        "printf('statistics.high', statistics.median_high(x_with_nan))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNPfNw8yOKtG"
      },
      "source": [
        "### Mode\n",
        "\n",
        "$$\\mathrm{M_o} = l + \\left( \\frac{f_1 - f_0}{2f_1 - f_0 - f_2} \\right)h$$\n",
        "\n",
        "$Where,$\n",
        "\n",
        "$l = lower\\ limit\\ of\\ the\\ modal\\ class$\n",
        "\n",
        "$f_1 = frequency\\ of\\ the\\ modal\\ class$\n",
        "\n",
        "$f_0 = frequency\\ of\\ the\\ class\\ preceding\\ the\\ modal\\ class$\n",
        "\n",
        "$f_2 = frequency\\ of\\ the\\ class\\ succeeding\\ the\\ modal\\ class$\n",
        "\n",
        "$h = size\\ of\\ the\\ class\\ interval\\ (assuming\\ all\\ class\\ sizes\\ to\\ be\\ equal).$\n",
        "\n",
        "The sample mode is the value in the dataset that occurs most frequently. If there isn‚Äôt a single such value, then the set is multimodal since it has multiple modal values. For example, in the set that contains the points 2, 3, 2, 8, and 12, the number 2 is the mode because it occurs twice, unlike the other items that occur only once.\n",
        "\n",
        "This is how you can get the mode with pure Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9WWU0gnMOKtG",
        "outputId": "c42484d2-a982-4404-b6f0-8c18f84eae13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : 2\n",
            "statistics           : 2\n",
            "scipy                : ModeResult(mode=array([2]), count=array([2]))\n",
            "scipy                : (array([2]), array([2]))\n"
          ]
        }
      ],
      "source": [
        "u = [2, 3, 2, 8, 12]\n",
        "printf('Python', max((u.count(item), item) for item in set(u))[1])\n",
        "printf('statistics', statistics.mode(u))\n",
        "printf('scipy', scipy.stats.mode(u))\n",
        "printf('scipy', (scipy.stats.mode(u).mode, scipy.stats.mode(u).count))\n",
        "# print(statistics.multimode(u))  # Python 3.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "K9QTbky_OKtG",
        "outputId": "40768f77-d601-4218-f7af-c708bc42fb87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12, 12, 12, 15, 15, 15, 21]\n",
            "\n",
            "ModeResult(mode=array([12]), count=array([3]))\n",
            "[12] [3]\n"
          ]
        }
      ],
      "source": [
        "v = [12, 15, 12, 15, 21, 15, 12]\n",
        "print(sorted(v))\n",
        "print()\n",
        "# print(statistics.mode(v))  # StatisticsError: no unique mode; found 2 equally common values\n",
        "# print(statistics.multimode(v))  # Python 3.8\n",
        "print(scipy.stats.mode(v))\n",
        "print(scipy.stats.mode(v).mode, scipy.stats.mode(v).count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HnVLLR4kOKtG"
      },
      "outputs": [],
      "source": [
        "mode_result = scipy.stats.mode(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VK5SSyMOKtH",
        "outputId": "1c879e23-34f1-41f5-c6db-d150ca10d6ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([12])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mode_result.mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y5fsnKDOKtH",
        "outputId": "25ff46e6-7c3d-46bf-e3c7-e8b223020601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "nan\n"
          ]
        }
      ],
      "source": [
        "print(statistics.mode([2, math.nan, 2]))\n",
        "# print(statistics.multimode([2, math.nan, 2]))\n",
        "print(statistics.mode([2, math.nan, 0, math.nan, 5]))\n",
        "# print(statistics.multimode([2, math.nan, 0, math.nan, 5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cEzT9n0OKtH",
        "outputId": "3ee9b369-7beb-48ec-e2b7-93152dfc8156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 2, 3, 8, 12]\n",
            "[12, 12, 12, 15, 15, 15, 21]\n"
          ]
        }
      ],
      "source": [
        "print(sorted(u))\n",
        "print(sorted(v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InsJibJ-OKtH",
        "outputId": "b3aaabae-b114-40f3-d857-1e4b0b96fa02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    2\n",
            "dtype: int64\n",
            "0    12\n",
            "1    15\n",
            "dtype: int64\n",
            "0    2.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "u_ser, v_ser, w_ser = pd.Series(u), pd.Series(v), pd.Series([2, 2, math.nan])\n",
        "print(u_ser.mode())\n",
        "print(v_ser.mode())\n",
        "print(w_ser.mode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fHeg3PrOKtH",
        "outputId": "11f016f7-4002-4355-bc3a-34746e67b928"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    2.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series([2, 2, math.nan, math.nan, math.nan]).mode()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpejkMj2OKtH"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTFUFF3SOKtH"
      },
      "source": [
        "### Measures of Variability\n",
        "The measures of central tendency aren‚Äôt sufficient to describe data. You‚Äôll also need the measures of variability that quantify the spread of data points. In this section, you‚Äôll learn how to identify and calculate the following variability measures:\n",
        "- Variance\n",
        "- Standard deviation\n",
        "- Skewness\n",
        "- Percentiles\n",
        "- Ranges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpg6g5IyOKtI"
      },
      "source": [
        "### Variance\n",
        "\n",
        "$$s^2 = \\frac{\\sum_{i=1}^N (x_i - \\bar{x})^2}{N-1}$$\n",
        "\n",
        "The sample variance quantifies the spread of the data. It shows numerically how far the data points are from the mean. You can express the sample variance of the dataset ùë• with ùëõ elements mathematically as ùë†¬≤ = Œ£·µ¢(ùë•·µ¢ ‚àí mean(ùë•))¬≤ / (ùëõ ‚àí 1), where ùëñ = 1, 2, ‚Ä¶, ùëõ and mean(ùë•) is the sample mean of ùë•. If you want to understand deeper why you divide the sum with ùëõ ‚àí 1 instead of ùëõ, then you can dive deeper into Bessel‚Äôs correction.\n",
        "\n",
        "The following figure shows you why it‚Äôs important to consider the variance when describing datasets:\n",
        "\n",
        "<img src=\"images/variance.png\">\n",
        "\n",
        "here are two datasets in this figure:\n",
        "\n",
        "- Green dots: This dataset has a smaller variance or a smaller average difference from the mean. It also has a smaller range or a smaller difference between the largest and smallest item.\n",
        "- White dots: This dataset has a larger variance or a larger average difference from the mean. It also has a bigger range or a bigger difference between the largest and smallest item.\n",
        "\n",
        "Note that these two datasets have the same mean and median, even though they appear to differ significantly. Neither the mean nor the median can describe this difference. That‚Äôs why you need the measures of variability.\n",
        "\n",
        "Here‚Äôs how you can calculate the sample variance with pure Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zogZd8f7OKtI"
      },
      "outputs": [],
      "source": [
        "n = len(x)\n",
        "mean_ = sum(x) / n\n",
        "var_ = sum((item - mean_)**2 for item in x) / (n - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWvcAVwCOKtI",
        "outputId": "1d7de478-10e5-4ae7-9376-8839e5025d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : 123.19999999999999\n",
            "statistics           : 123.2\n",
            "numpy                : 123.19999999999999\n",
            "Series               : 123.19999999999999\n"
          ]
        }
      ],
      "source": [
        "printf('Python', var_)\n",
        "printf('statistics', statistics.variance(x))\n",
        "printf('numpy', np.var(x, ddof=1))\n",
        "\n",
        "printf('Series', pd.Series(x).var(ddof=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLWylfGXOKtI"
      },
      "source": [
        "It‚Äôs very important to specify the parameter ddof=1. That‚Äôs how you set the delta degrees of freedom to 1. This parameter allows the proper calculation of ùë†¬≤, with (ùëõ ‚àí 1) in the denominator instead of ùëõ.\n",
        "\n",
        "If you have nan values in the dataset, then np.var() will return nan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0v9Qc0POKtI",
        "outputId": "6f3e96e3-20fe-4468-b343-f37477d4259e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "statistics           : nan\n",
            "numpy                : nan\n"
          ]
        }
      ],
      "source": [
        "printf('statistics', statistics.variance(x_with_nan))\n",
        "printf('numpy', np.var(x_with_nan, ddof=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp6Wki3JOKtI",
        "outputId": "0946990c-50a6-4fce-c1de-3df2e9cb2739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numpy.nan            : 123.19999999999999\n",
            "Series               : 123.19999999999999\n"
          ]
        }
      ],
      "source": [
        "printf('numpy.nan', np.nanvar(x_with_nan, ddof=1))\n",
        "\n",
        "printf('Series', pd.Series(x_with_nan).var(ddof=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyhzqw_YOKtJ"
      },
      "source": [
        "You calculate the population variance similarly to the sample variance. However, you have to use ùëõ in the denominator instead of ùëõ ‚àí 1: Œ£·µ¢(ùë•·µ¢ ‚àí mean(ùë•))¬≤ / ùëõ. In this case, ùëõ is the number of items in the entire population. You can get the population variance similar to the sample variance, with the following differences:\n",
        "\n",
        "- Replace (n - 1) with n in the pure Python implementation.\n",
        "- Use statistics.pvariance() instead of statistics.variance().\n",
        "- Specify the parameter ddof=0 if you use NumPy or Pandas. In NumPy, you can omit ddof because its default value is 0.\n",
        "\n",
        "Note that you should always be aware of whether you‚Äôre working with a sample or the entire population whenever you‚Äôre calculating the variance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZcuzWBoOKtJ"
      },
      "source": [
        "### Standard Deviation\n",
        "\n",
        "$$s = \\sqrt{s^2} = \\sqrt{\\frac{\\sum_{i=1}^N (x_i - \\bar{x})^2}{N-1}}$$\n",
        "\n",
        "The sample standard deviation is another measure of data spread. It‚Äôs connected to the sample variance, as standard deviation, ùë†, is the positive square root of the sample variance. The standard deviation is often more convenient than the variance because it has the same unit as the data points. Once you get the variance, you can calculate the standard deviation with pure Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EjmJqc-DOKtJ"
      },
      "outputs": [],
      "source": [
        "std_ = var_ ** 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPggyTb2OKtJ",
        "outputId": "a6737df6-9d00-4150-ce4b-7e3306725ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : 11.099549540409285\n",
            "statistics           : 11.099549540409287\n",
            "numpy                : 11.099549540409285\n",
            "numpy                : 11.099549540409285\n"
          ]
        }
      ],
      "source": [
        "printf('Python', std_)\n",
        "printf('statistics', statistics.stdev(x))\n",
        "printf('numpy', np.std(x, ddof=1))\n",
        "printf('numpy', np.array(x).std(ddof=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2cM9GGVOKtJ",
        "outputId": "a5de7663-678e-43ad-8855-97efb1921360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numpy                : nan\n",
            "numpy                : nan\n"
          ]
        }
      ],
      "source": [
        "printf('numpy', np.std(x_with_nan, ddof=1))\n",
        "printf('numpy', np.array(x_with_nan).std(ddof=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCq-JhsEOKtJ",
        "outputId": "b385a452-b465-4946-aec8-3fa24639e4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numpy.nan            : 11.099549540409285\n",
            "numpy.nan            : 11.099549540409285\n"
          ]
        }
      ],
      "source": [
        "printf('numpy.nan', np.nanstd(x_with_nan, ddof=1))\n",
        "\n",
        "printf('numpy.nan', pd.Series(x_with_nan).std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knR7OUagOKtJ"
      },
      "source": [
        "The population standard deviation refers to the entire population. It‚Äôs the positive square root of the population variance. You can calculate it just like the sample standard deviation, with the following differences:\n",
        "\n",
        "- Find the square root of the population variance in the pure Python implementation.\n",
        "- Use statistics.pstdev() instead of statistics.stdev().\n",
        "- Specify the parameter ddof=0 if you use NumPy or Pandas. In NumPy, you can omit ddof because its default value is 0.\n",
        "\n",
        "As you can see, you can determine the standard deviation in Python, NumPy, and Pandas in almost the same way as you determine the variance. You use different but analogous functions and methods with the same arguments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FynmmuSDOKtK"
      },
      "source": [
        "__Variance__ helps to find the distribution of data in a population from a _mean_, and __standard deviation__ also helps to know the distribution of data in population, but __standard deviation__ gives more clarity about the __deviation__ of data from a _mean_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etOLszOsOKtK"
      },
      "source": [
        "### Skewness\n",
        "\n",
        "$$\\begin{align}\n",
        "G_1 & = \\frac{k_3}{k_2^{3/2}} = \\frac{n^2}{(n-1)(n-2)}\\; \\frac{m_3}{s^3} = \\frac{\\sqrt{n(n-1)}}{n-2} \\frac{m_3}{m_2^{3/2}} = \\frac{\\sqrt{n(n-1)}}{n-2} \\left[ \\frac{\\frac{1}{n}\\sum\\limits_{i=1}^n {(x_i-\\bar{x})}^3}{\\left( \\frac{1}{n} \\sum\\limits_{i=1}^n (x_i-\\bar{x})^2 \\right)^{3/2}} \\right] \\\\\n",
        "\\end{align}$$\n",
        "\n",
        "The sample skewness measures the asymmetry of a data sample.\n",
        "\n",
        "There are several mathematical definitions of skewness. One common expression to calculate the skewness of the dataset ùë• with ùëõ elements is (ùëõ¬≤ / ((ùëõ ‚àí 1)(ùëõ ‚àí 2))) (Œ£·µ¢(ùë•·µ¢ ‚àí mean(ùë•))¬≥ / (ùëõùë†¬≥)). A simpler expression is Œ£·µ¢(ùë•·µ¢ ‚àí mean(ùë•))¬≥ ùëõ / ((ùëõ ‚àí 1)(ùëõ ‚àí 2)ùë†¬≥), where ùëñ = 1, 2, ‚Ä¶, ùëõ and mean(ùë•) is the sample mean of ùë•. The skewness defined like this is called the adjusted Fisher-Pearson standardized moment coefficient.\n",
        "\n",
        "The previous figure showed two datasets that were quite symmetrical. In other words, their points had similar distances from the mean. In contrast, the following image illustrates two asymmetrical sets:\n",
        "\n",
        "<img src=\"images/skewness.png\">\n",
        "\n",
        "The first set is represented by the green dots and the second with the white ones. Usually, negative skewness values indicate that there‚Äôs a dominant tail on the left side, which you can see with the first set. Positive skewness values correspond to a longer or fatter tail on the right side, which you can see in the second set. If the skewness is close to 0 (for example, between ‚àí0.5 and 0.5), then the dataset is considered quite symmetrical.\n",
        "\n",
        "Once you‚Äôve calculated the size of your dataset n, the sample mean mean_, and the standard deviation std_, you can get the sample skewness with pure Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ayEGZXfWOKtK"
      },
      "outputs": [],
      "source": [
        "x = [8.0, 1, 2.5, 4, 28.0]\n",
        "n = len(x)\n",
        "mean_ = sum(x) / n\n",
        "var_ = sum((item - mean_)**2 for item in x) / (n - 1)\n",
        "std_ = var_ ** 0.5\n",
        "skew_ = (sum((item - mean_)**3 for item in x) * n / ((n - 1) * (n - 2) * std_**3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU_zk6EdOKtK",
        "outputId": "95bd0d9c-634a-436c-8851-fa7d41517a29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python               : 1.9470432273905929\n",
            "scipy                : 1.9470432273905927\n",
            "scipy                : nan\n"
          ]
        }
      ],
      "source": [
        "printf('Python', skew_)\n",
        "printf('scipy', scipy.stats.skew(x, bias=False))\n",
        "printf('scipy', scipy.stats.skew(x_with_nan, bias=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McqQVIhFOKtK"
      },
      "source": [
        "The obtained result is the same as the pure Python implementation. The parameter bias is set to False to enable the corrections for statistical bias. The optional parameter nan_policy can take the values 'propagate', 'raise', or 'omit'. It allows you to control how you‚Äôll handle nan values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCrgYUomOKtK"
      },
      "source": [
        "### Percentiles\n",
        "\n",
        "$$n =  \\left \\lceil \\frac{P}{100} \\times N  \\right \\rceil$$\n",
        "\n",
        "The sample ùëù percentile is the element in the dataset such that ùëù% of the elements in the dataset are less than or equal to that value. Also, (100 ‚àí ùëù)% of the elements are greater than or equal to that value. If there are two such elements in the dataset, then the sample ùëù percentile is their arithmetic mean. Each dataset has three quartiles, which are the percentiles that divide the dataset into four parts:\n",
        "\n",
        "- The first quartile is the sample 25th percentile. It divides roughly 25% of the smallest items from the rest of the dataset.\n",
        "- The second quartile is the sample 50th percentile or the median. Approximately 25% of the items lie between the first and second quartiles and another 25% between the second and third quartiles.\n",
        "- The third quartile is the sample 75th percentile. It divides roughly 25% of the largest items from the rest of the dataset.\n",
        "\n",
        "Each part has approximately the same number of items. If you want to divide your data into several intervals, then you can use statistics.quantiles():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejCXJkmtOKtL",
        "outputId": "bfbf0e32-a785-43bf-a7e2-f14571563d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-3.44\n",
            "34.919999999999995\n"
          ]
        }
      ],
      "source": [
        "x = [-5.0, -1.1, 0.1, 2.0, 8.0, 12.8, 21.0, 25.8, 41.0]\n",
        "# print(statistics.quantiles(x, n=2)) # Python 3.8\n",
        "# print(statistics.quantiles(x, n=4, method='inclusive'))\n",
        "\n",
        "print(np.percentile(x, 5))\n",
        "print(np.percentile(x, 95))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HBF1oQVOKtL",
        "outputId": "54581399-ea34-4fdc-993a-91486c016776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.1  8.  21. ]\n",
            "8.0\n"
          ]
        }
      ],
      "source": [
        "print(np.percentile(x, [25, 50, 75]))\n",
        "print(np.median(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW1jJEFoOKtL",
        "outputId": "cf1f9133-1f69-4c9c-acf1-af2da42db4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.1  8.  21. ]\n"
          ]
        }
      ],
      "source": [
        "x_with_nan = np.insert(x, 2, np.nan)\n",
        "print(np.nanpercentile(x_with_nan, [25, 50, 75]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFA__rGIOKtL",
        "outputId": "650bf0dc-7711-4efe-8bfe-1cc195ed01c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-3.44\n",
            "34.919999999999995\n",
            "[ 0.1  8.  21. ]\n",
            "[ 0.1  8.  21. ]\n"
          ]
        }
      ],
      "source": [
        "print(np.quantile(x, 0.05))\n",
        "print(np.quantile(x, 0.95))\n",
        "print(np.quantile(x, [0.25, 0.5, 0.75]))\n",
        "print(np.nanquantile(x_with_nan, [0.25, 0.5, 0.75]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss64gZmBOKtL"
      },
      "source": [
        "### Ranges\n",
        "\n",
        "$$R = x_\\mathrm{max} - x_\\mathrm{min}$$\n",
        "\n",
        "The range of data is the difference between the maximum and minimum element in the dataset. You can get it with the function np.ptp():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9H9DbxjOKtL",
        "outputId": "70c3a0be-4e5e-4399-cd8b-c952acad2415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46.0\n",
            "nan\n"
          ]
        }
      ],
      "source": [
        "print(np.ptp(x))\n",
        "print(np.ptp(x_with_nan))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jJotezzOKtL"
      },
      "source": [
        "Alternatively, you can use built-in Python, NumPy, or Pandas functions and methods to calculate the maxima and minima of sequences:\n",
        "\n",
        "- max() and min() from the Python standard library\n",
        "- amax() and amin() from NumPy\n",
        "- nanmax() and nanmin() from NumPy to ignore nan values\n",
        "- .max() and .min() from NumPy\n",
        "- .max() and .min() from Pandas to ignore nan values by default\n",
        "\n",
        "Here are some examples of how you would use these routines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yrNZf-HOKtM",
        "outputId": "052a12cf-cd43-481a-daaa-ac9dbb39ca43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46.0\n",
            "46.0\n",
            "46.0\n",
            "46.0\n"
          ]
        }
      ],
      "source": [
        "print(max(x) - min(x))\n",
        "print(np.amax(x) - np.amin(x))\n",
        "print(np.nanmax(x_with_nan) - np.nanmin(x_with_nan))\n",
        "print(np.array(x).max() - np.array(x).min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnKOoxKvOKtM",
        "outputId": "d7271c8b-3be5-4bfd-9ce9-5cdaf8ff5a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46.0\n",
            "46.0\n"
          ]
        }
      ],
      "source": [
        "print(pd.Series(x).max() - pd.Series(x).min())\n",
        "print(pd.Series(x_with_nan).max() - pd.Series(x_with_nan).min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xFS_YBnOKtM"
      },
      "source": [
        "The interquartile range is the difference between the first and third quartile. Once you calculate the quartiles, you can take their difference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "hY4edkNfOKtM",
        "outputId": "a5daa382-216b-4c15-c0ce-7d30c6ddc998"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20.9"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "quartiles = np.quantile(x, [0.25, 0.75])\n",
        "quartiles[1] - quartiles[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWH_MpSrOKtM"
      },
      "source": [
        "### Summary of Descriptive Statistics\n",
        "SciPy and Pandas offer useful routines to quickly get descriptive statistics with a single function or method call. You can use scipy.stats.describe() like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROhULWFQOKtM",
        "outputId": "ae9f36e6-9293-4118-8a6c-143d9948e0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DescribeResult(nobs=9, minmax=(-5.0, 41.0), mean=11.622222222222222, variance=228.75194444444446, skewness=0.9249043136685094, kurtosis=0.14770623629658886)\n"
          ]
        }
      ],
      "source": [
        "result = scipy.stats.describe(x, ddof=1, bias=False)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbbAFmBmOKtN"
      },
      "source": [
        "You have to provide the dataset as the first argument. The argument can be a NumPy array, list, tuple, or similar data structure. You can omit ddof=1 since it‚Äôs the default and only matters when you‚Äôre calculating the variance. You can pass bias=False to force correcting the skewness and kurtosis for statistical bias.\n",
        "\n",
        "Note: The optional parameter nan_policy can take the values 'propagate' (default), 'raise' (an error), or 'omit'. This parameter allows you to control what‚Äôs happening when there are nan values.\n",
        "\n",
        "describe() returns an object that holds the following descriptive statistics:\n",
        "\n",
        "- nobs: the number of observations or elements in your dataset\n",
        "- minmax: the tuple with the minimum and maximum values of your dataset\n",
        "- mean: the mean of your dataset\n",
        "- variance: the variance of your dataset\n",
        "- skewness: the skewness of your dataset\n",
        "- kurtosis: the kurtosis of your dataset\n",
        "\n",
        "You can access particular values with dot notation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX0XMS_mOKtN",
        "outputId": "2d72463b-6aa9-4024-de42-037a5a4a7134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "-5.0\n",
            "41.0\n",
            "11.622222222222222\n",
            "228.75194444444446\n",
            "0.9249043136685094\n",
            "0.14770623629658886\n"
          ]
        }
      ],
      "source": [
        "print(result.nobs)\n",
        "print(result.minmax[0])  # Min\n",
        "print(result.minmax[1])  # Max\n",
        "print(result.mean)\n",
        "print(result.variance)\n",
        "print(result.skewness)\n",
        "print(result.kurtosis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcy6fWlCOKtN"
      },
      "source": [
        "Pandas has similar, if not better, functionality. Series objects have the method .describe():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wehpBD_JOKtN",
        "outputId": "da101d5c-39d0-43ef-e0eb-c6b969ce1282"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count     9.000000\n",
              "mean     11.622222\n",
              "std      15.124548\n",
              "min      -5.000000\n",
              "25%       0.100000\n",
              "50%       8.000000\n",
              "75%      21.000000\n",
              "max      41.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = pd.Series(x).describe()\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDQlHvlfOKtN"
      },
      "source": [
        "It returns a new Series that holds the following:\n",
        "\n",
        "- count: the number of elements in your dataset\n",
        "- mean: the mean of your dataset\n",
        "- std: the standard deviation of your dataset\n",
        "- min and max: the minimum and maximum values of your dataset\n",
        "- 25%, 50%, and 75%: the quartiles of your dataset\n",
        "\n",
        "If you want the resulting Series object to contain other percentiles, then you should specify the value of the optional parameter percentiles. You can access each item of result with its label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8xy5gpjOKtN",
        "outputId": "7478f6b7-3e8f-4b46-b321-c231de623125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.622222222222222\n",
            "15.12454774346805\n",
            "-5.0\n",
            "41.0\n",
            "0.1\n",
            "8.0\n",
            "21.0\n"
          ]
        }
      ],
      "source": [
        "print(result['mean'])\n",
        "print(result['std'])\n",
        "print(result['min'])\n",
        "print(result['max'])\n",
        "print(result['25%'])\n",
        "print(result['50%'])\n",
        "print(result['75%'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmpFVqxXOKtO"
      },
      "source": [
        "### Boxplot & Outliers\n",
        "\n",
        "<img src=\"images/boxplot.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO9so_yHOKtO"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdtXBQ8gOKtO"
      },
      "source": [
        "### Measures of Correlation Between Pairs of Data\n",
        "You‚Äôll often need to examine the relationship between the corresponding elements of two variables in a dataset. Say there are two variables, ùë• and ùë¶, with an equal number of elements, ùëõ. Let ùë•‚ÇÅ from ùë• correspond to ùë¶‚ÇÅ from ùë¶, ùë•‚ÇÇ from ùë• to ùë¶‚ÇÇ from ùë¶, and so on. You can then say that there are ùëõ pairs of corresponding elements: (ùë•‚ÇÅ, ùë¶‚ÇÅ), (ùë•‚ÇÇ, ùë¶‚ÇÇ), and so on.\n",
        "\n",
        "You‚Äôll see the following measures of correlation between pairs of data:\n",
        "\n",
        "Positive correlation exists when larger values of ùë• correspond to larger values of ùë¶ and vice versa.\n",
        "Negative correlation exists when larger values of ùë• correspond to smaller values of ùë¶ and vice versa.\n",
        "Weak or no correlation exists if there is no such apparent relationship.\n",
        "The following figure shows examples of negative, weak, and positive correlation:\n",
        "\n",
        "<img src=\"images/correlation.png\">\n",
        "\n",
        "The plot on the left with the red dots shows negative correlation. The plot in the middle with the green dots shows weak correlation. Finally, the plot on the right with the blue dots shows positive correlation.\n",
        "\n",
        "<br>\n",
        "<font color='blue'>_Note: There‚Äôs one important thing you should always have in mind when working with correlation among a pair of variables, and that‚Äôs that correlation is not a measure or indicator of causation, but only of association!_</font>\n",
        "\n",
        "The two statistics that measure the correlation between datasets are covariance and the correlation coefficient. Let‚Äôs define some data to work with these measures. You‚Äôll create two Python lists and use them to get corresponding NumPy arrays and Pandas Series:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bJ71cmlGOKtO"
      },
      "outputs": [],
      "source": [
        "x = list(range(-10, 11))\n",
        "y = [0, 2, 2, 2, 2, 3, 3, 6, 7, 4, 7, 6, 6, 9, 4, 5, 5, 10, 11, 12, 14]\n",
        "x_, y_ = np.array(x), np.array(y)\n",
        "x__, y__ = pd.Series(x_), pd.Series(y_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stfekzmuOKtO"
      },
      "source": [
        "Now that you have the two variables, you can start exploring the relationship between them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bww0ys7VOKtO"
      },
      "source": [
        "### Covariance\n",
        "The sample covariance is a measure that quantifies the strength and direction of a relationship between a pair of variables:\n",
        "\n",
        "- If the correlation is positive, then the covariance is positive, as well. A stronger relationship corresponds to a higher value of the covariance.\n",
        "- If the correlation is negative, then the covariance is negative, as well. A stronger relationship corresponds to a lower (or higher absolute) value of the covariance.\n",
        "- If the correlation is weak, then the covariance is close to zero.\n",
        "\n",
        "The covariance of the variables ùë• and ùë¶ is mathematically defined as ùë†À£ ∏ = Œ£·µ¢ (ùë•·µ¢ ‚àí mean(ùë•)) (ùë¶·µ¢ ‚àí mean(ùë¶)) / (ùëõ ‚àí 1), where ùëñ = 1, 2, ‚Ä¶, ùëõ, mean(ùë•) is the sample mean of ùë•, and mean(ùë¶) is the sample mean of ùë¶. It follows that the covariance of two identical variables is actually the variance: ùë†À£À£ = Œ£·µ¢(ùë•·µ¢ ‚àí mean(ùë•))¬≤ / (ùëõ ‚àí 1) = (ùë†À£)¬≤ and ùë† ∏ ∏ = Œ£·µ¢(ùë¶·µ¢ ‚àí mean(ùë¶))¬≤ / (ùëõ ‚àí 1) = (ùë† ∏)¬≤.\n",
        "\n",
        "This is how you can calculate the covariance in pure Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji0tfOBaOKtP",
        "outputId": "0d812cef-92e4-4945-e48b-88bc41368ef6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19.95"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n = len(x)\n",
        "mean_x, mean_y = sum(x) / n, sum(y) / n\n",
        "cov_xy = (sum((x[k] - mean_x) * (y[k] - mean_y) for k in range(n)) / (n - 1))\n",
        "cov_xy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIJ7Z4ygOKtP"
      },
      "source": [
        "First, you have to find the mean of x and y. Then, you apply the mathematical formula for the covariance.\n",
        "\n",
        "NumPy has the function cov() that returns the covariance matrix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GtdcdqyOKtP",
        "outputId": "cacc806a-a881-4f05-a14b-29748edaf6df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[38.5       , 19.95      ],\n",
              "       [19.95      , 13.91428571]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cov_matrix = np.cov(x_, y_)\n",
        "cov_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj5ShewZOKtP"
      },
      "source": [
        "Note that cov() has the optional parameters bias, which defaults to False, and ddof, which defaults to None. Their default values are suitable for getting the sample covariance matrix. The upper-left element of the covariance matrix is the covariance of x and x, or the variance of x. Similarly, the lower-right element is the covariance of y and y, or the variance of y. You can check to see that this is true:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aT6eP1SOKtP",
        "outputId": "93c1006a-0580-4c3d-dd93-8af350cf8cbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38.5\n",
            "13.914285714285711\n"
          ]
        }
      ],
      "source": [
        "print(x_.var(ddof=1))\n",
        "print(y_.var(ddof=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYYDQOkEOKtP"
      },
      "source": [
        "As you can see, the variances of x and y are equal to cov_matrix[0, 0] and cov_matrix[1, 1], respectively.\n",
        "\n",
        "The other two elements of the covariance matrix are equal and represent the actual covariance between x and y:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjxfwWjBOKtQ",
        "outputId": "36dff438-3be2-4201-f645-8bb63506b81a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19.950000000000003\n",
            "19.950000000000003\n"
          ]
        }
      ],
      "source": [
        "cov_xy = cov_matrix[0, 1]\n",
        "print(cov_xy)\n",
        "cov_xy = cov_matrix[1, 0]\n",
        "print(cov_xy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwpm38fIOKtQ"
      },
      "source": [
        "You‚Äôve obtained the same value of the covariance with np.cov() as with pure Python.\n",
        "\n",
        "Pandas Series have the method .cov() that you can use to calculate the covariance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9otZfaKTOKtQ",
        "outputId": "802eb66e-455a-473b-c240-5487d95080c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19.950000000000003\n",
            "19.950000000000003\n"
          ]
        }
      ],
      "source": [
        "cov_xy = x__.cov(y__)\n",
        "print(cov_xy)\n",
        "cov_xy = y__.cov(x__)\n",
        "print(cov_xy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFpFzBgCOKtQ"
      },
      "source": [
        "### Correlation Coefficient\n",
        "The correlation coefficient, or Pearson product-moment correlation coefficient, is denoted by the symbol ùëü. The coefficient is another measure of the correlation between data. You can think of it as a standardized covariance. Here are some important facts about it:\n",
        "\n",
        "- The value ùëü > 0 indicates positive correlation.\n",
        "- The value ùëü < 0 indicates negative correlation.\n",
        "- The value r = 1 is the maximum possible value of ùëü. It corresponds to a perfect positive linear relationship between variables.\n",
        "- The value r = ‚àí1 is the minimum possible value of ùëü. It corresponds to a perfect negative linear relationship between variables.\n",
        "- The value r ‚âà 0, or when ùëü is around zero, means that the correlation between variables is weak.\n",
        "\n",
        "The mathematical formula for the correlation coefficient is ùëü = ùë†À£ ∏ / (ùë†À£ùë† ∏) where ùë†À£ and ùë† ∏ are the standard deviations of ùë• and ùë¶ respectively. If you have the means (mean_x and mean_y) and standard deviations (std_x, std_y) for the datasets x and y, as well as their covariance cov_xy, then you can calculate the correlation coefficient with pure Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrlHCxBZOKtQ",
        "outputId": "4b37fdcf-47f2-4eb0-c99d-729ca3943ca6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8619500056316062"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "var_x = sum((item - mean_x)**2 for item in x) / (n - 1)\n",
        "var_y = sum((item - mean_y)**2 for item in y) / (n - 1)\n",
        "std_x, std_y = var_x ** 0.5, var_y ** 0.5\n",
        "r = cov_xy / (std_x * std_y)\n",
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK8OEICCOKtQ"
      },
      "source": [
        "You‚Äôve got the variable r that represents the correlation coefficient.\n",
        "\n",
        "scipy.stats has the routine pearsonr() that calculates the correlation coefficient and the ùëù-value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmn4WyNjOKtR",
        "outputId": "bffb05fb-9795-4c1a-e2ee-7c3e221dda2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8619500056316061\n",
            "5.122760847201135e-07\n"
          ]
        }
      ],
      "source": [
        "r, p = scipy.stats.pearsonr(x_, y_)\n",
        "print(r)\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p4Me0-kOKtR"
      },
      "source": [
        "pearsonr() returns a tuple with two numbers. The first one is ùëü and the second is the ùëù-value.\n",
        "\n",
        "_* The P-value is the probability that you would have found the current result if the correlation coefficient were in fact zero (null hypothesis). If this probability is lower than the conventional 5% (P<0.05) the correlation coefficient is called statistically significant._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CoYQwueOKtR"
      },
      "source": [
        "Similar to the case of the covariance matrix, you can apply np.corrcoef() with x_ and y_ as the arguments and get the correlation coefficient matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUB58R_ZOKtR",
        "outputId": "33745482-0eff-4fb1-ea5c-ed4ed27f7ce4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.86195001],\n",
              "       [0.86195001, 1.        ]])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix = np.corrcoef(x_, y_)\n",
        "corr_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WkCZNpKOKtR"
      },
      "source": [
        "The upper-left element is the correlation coefficient between x_ and x_. The lower-right element is the correlation coefficient between y_ and y_. Their values are equal to 1.0. The other two elements are equal and represent the actual correlation coefficient between x_ and y_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miwLD_0NOKtR",
        "outputId": "6a362cac-5c87-4b77-cc42-d635edbfaa15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8619500056316062\n",
            "0.8619500056316062\n"
          ]
        }
      ],
      "source": [
        "r = corr_matrix[0, 1]\n",
        "print(r)\n",
        "r = corr_matrix[1, 0]\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIO4lzp5OKtS"
      },
      "source": [
        "Of course, the result is the same as with pure Python and pearsonr().\n",
        "\n",
        "You can get the correlation coefficient with scipy.stats.linregress():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Rb9X3RFmOKtS",
        "outputId": "d8593fa1-4c21-4b2b-bff8-2d5a4689dc37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinregressResult(slope=0.5181818181818182, intercept=5.714285714285714, rvalue=0.8619500056316061, pvalue=5.122760847201128e-07, stderr=0.06992387660074978)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scipy.stats.linregress(x_, y_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liJsmfo3OKtS"
      },
      "source": [
        "linregress() takes x_ and y_, performs linear regression, and returns the results. slope and intercept define the equation of the regression line, while rvalue is the correlation coefficient. To access particular values from the result of linregress(), including the correlation coefficient, use dot notation:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f40p56S2OKtS",
        "outputId": "5f0f8213-c520-4aca-b348-d0eaa348f2f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8619500056316061"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = scipy.stats.linregress(x_, y_)\n",
        "r = result.rvalue\n",
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T4v5QY_OKtS"
      },
      "source": [
        "That‚Äôs how you can perform linear regression and obtain the correlation coefficient.\n",
        "\n",
        "Pandas Series have the method .corr() for calculating the correlation coefficient:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Hm3o0PJOKtS",
        "outputId": "9398a362-bb78-44b1-8921-a25547854bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8619500056316062\n",
            "0.8619500056316062\n"
          ]
        }
      ],
      "source": [
        "r = x__.corr(y__)\n",
        "print(r)\n",
        "r = y__.corr(x__)\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ukw64LagOKtS"
      },
      "source": [
        "### Additional information about Chi-squared test\n",
        "* [Simple Explanation of Chi-Squared](https://www.youtube.com/watch?v=VskmMgXmkMQ&ab_channel=JDavidEisenberg)\n",
        "* [Choosing A Statistical Test Based On Your Data And Research Question](https://www.youtube.com/watch?v=9-Y6wIMxExI&ab_channel=ResearchHUB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "geQGHXaFOKtT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Rj-WHom4OKtT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}